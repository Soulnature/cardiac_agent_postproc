# 1. Introduction

Accurate segmentation of cardiac magnetic resonance imaging (MRI) is essential for quantifying clinical indices such as ventricular volume and ejection fraction [3]. In recent years, deep learning (DL) methods—particularly convolutional neural networks (e.g., nnU-Net [1]) and vision transformers—have established automated cardiac MRI segmentation as a highly successful application of medical artificial intelligence. Despite achieving high pixel-wise overlap (Dice scores) on in-distribution data, these models suffer from significant performance degradation when deployed on out-of-distribution (OOD) scans originating from different clinical centers, distinct scanner vendors, or cohorts with rare pathologies [2]. Under such domain shifts, DL models frequently produce segmentations afflicted with severe anatomical and topological violations. Common failure modes include disconnected myocardial components, missing ventricles, or structurally impossible fusions of the right and left ventricles. In clinical workflows, these implausible predictions necessitate tedious manual correction by expert radiologists, significantly impeding the translation of these algorithms into fully automated clinical pipelines.

To mitigate these limitations, various post-processing techniques and anatomically constrained models have been proposed. Traditional post-processing methods rely on morphological operations or Conditional Random Fields (CRF) [4], which improve local label smoothness but lack the high-level semantic context required to rectify complex structural anomalies. More advanced approaches incorporate deep shape priors, such as Anatomically Constrained Neural Networks (ACNNs) [5] or latent space projections via autoencoders [6], which constrain predictions to a learned manifold of anatomically valid shapes. However, these methods are intrinsically bottlenecked by their training paradigms: they require extensive and computationally expensive retraining to adapt to new domains, heavily depend on the availability of target-domain ground truth labels, and often fail to generalize when presented with novel pathological shapes or extreme OOD artifacts. A paradigm shift is thus required toward highly reasoning-capable, zero-shot post-processing systems that can comprehend and repair anatomical errors without necessitating the retraining of the underlying base segmentation models.

Recently, Large Language Models (LLMs) and Vision-Language Models (VLMs, e.g., GPT-4o) have revolutionized artificial intelligence by demonstrating unprecedented cognitive and visual reasoning capabilities [7, 8]. Concurrently, multi-agent frameworks (e.g., MetaGPT [9]) have explicitly shown that orchestrating specialized LLM agents in a collaborative environment can solve complex, multi-step tasks by mimicking expert human workflows. While such multi-agent systems have flourished in natural language processing and software engineering, their adaptation to complex, topology-aware medical image post-processing remains largely unexplored. The primary challenge lies in translating high-dimensional spatial anomalies and complex geometric constraints into actionable text-based policies that an LLM can parse and execute reliably [10].

In this paper, we bridge this gap by proposing the first Multi-Agent LLM/VLM Framework for the zero-shot, anatomy-aware post-processing of cardiac MRI segmentations. Inspired by the collaborative diagnostic workflow of clinical experts, we formulate segmentation refinement as a sequential decision process without ground truth labels. Our system orchestrates a cooperative team of six specialized agents (Coordinator, Triage, Diagnosis, Planner, Executor, Verifier) that explicitely utilizes the visual grounding capabilities of VLMs and the rule-based spatial reasoning of LLMs. Although our approach performs zero-shot inference—bypassing the need to retrain existing base segmentation models—it leverages few-shot in-context learning guided by a novel, reference-free Reward Quality Score (RQS) and a Visual Knowledge Base (VKB) compiled from a minimal curated reference set. Extensive evaluations on multi-center datasets demonstrate that our human-mimicking hierarchical workflow effectively detects anatomical defects, formulates step-by-step repair plans, and executes context-aware corrections, significantly improving the topological correctness and robustness of base model predictions against severe out-of-distribution failures.

---

### References (To be added to your bibliography)
[1] Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. *Nature methods*, 18(2), 203-211.
[2] Campello, V. M., et al. (2021). Multi-centre, multi-vendor and multi-disease cardiac segmentation: the M&Ms challenge. *IEEE Transactions on Medical Imaging*, 40(12), 3543-3554.
[3] Bernard, O., et al. (2018). Deep learning techniques for automatic MRI cardiac multi-structures segmentation and diagnosis: is the problem solved?. *IEEE Transactions on Medical Imaging*, 37(11), 2514-2525.
[4] Krahenbuhl, P., & Koltun, V. (2011). Efficient inference in fully connected crfs with gaussian edge potentials. *Advances in neural information processing systems*, 24.
[5] Oktay, O., et al. (2017). Anatomically constrained neural networks (ACNNs): application to cardiac image enhancement and segmentation. *IEEE Transactions on Medical Imaging*, 37(2), 384-395.
[6] Painchaud, N., et al. (2020). Cardiac segmentation with strong anatomical guarantees. *IEEE Transactions on Medical Imaging*, 39(11), 3703-3713.
[7] Moor, M., et al. (2023). Foundation models for generalist medical artificial intelligence. *Nature*, 616(7956), 259-265.
[8] Thirunavukarasu, A. J., et al. (2023). Large language models in medicine. *Nature medicine*, 29(8), 1930-1940.
[9] Hong, S., et al. (2023). MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework. *ICLR 2024*.
[10] Wei, J., et al. (2022). Chain-of-thought prompting elicits reasoning in large language models. *Advances in neural information processing systems*, 35, 24824-24837.
